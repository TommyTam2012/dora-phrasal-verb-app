console.log("ğŸŸ£ Dora Phrasal Verb script.js loaded successfully");

const responseBox = document.getElementById("responseBox");
const questionInput = document.getElementById("questionInput");
const historyList = document.getElementById("historyList");
const micBtn = document.getElementById("micBtn");

// ğŸˆ¶ Chinese translation box under the response
const translationBox = document.createElement("div");
translationBox.id = "chineseTranslation";
translationBox.style.marginTop = "10px";
translationBox.style.fontSize = "0.95em";
translationBox.style.color = "#333";
responseBox.insertAdjacentElement("afterend", translationBox);

let currentExamId = "";

// ================================================================
// Step 1: Open the selected phrasal verb PDF
// ================================================================
function setExam(examId) {
  currentExamId = examId;

  const pdfMap = {
    phrasal01: "https://github.com/TommyTam2012/dora-phrasal-verb-app/raw/main/public/exam/Phrasal1_2.pdf",
    phrasal02: "https://github.com/TommyTam2012/dora-phrasal-verb-app/raw/main/public/exam/Phrasal3_4.pdf",
    phrasal03: "https://github.com/TommyTam2012/dora-phrasal-verb-app/raw/main/public/exam/Phrasal5-6.pdf",
    phrasal04: "https://github.com/TommyTam2012/dora-phrasal-verb-app/raw/main/public/exam/Phrasal7_8.pdf"
  };

  const pdfUrl = pdfMap[examId];
  if (!pdfUrl) {
    alert("âš ï¸ è©²å–®å…ƒçš„ PDF å°šæœªä¸Šå‚³ã€‚");
    return;
  }

  const newTab = window.open("about:blank", "_blank");
  if (newTab) {
    newTab.location.href = pdfUrl;
    console.log(`ğŸ“˜ Opening: ${pdfUrl}`);
  } else {
    alert("âš ï¸ è«‹å…è¨±ç€è¦½å™¨é–‹å•Ÿæ–°åˆ†é ã€‚");
  }
}

// ================================================================
// Step 2: Clear conversation history
// ================================================================
function clearHistory() {
  historyList.innerHTML = "";
  console.log("ğŸ§¹ History cleared");
}

// ================================================================
// Step 3: Submit question to GPT
// ================================================================
async function submitQuestion() {
  const question = questionInput.value.trim();
  if (!question) {
    alert("âš ï¸ è«‹è¼¸å…¥è¦æŸ¥è©¢çš„ç‰‡èªå‹•è©");
    return;
  }

  responseBox.textContent = "æ­£åœ¨åˆ†æä¸­ï¼Œè«‹ç¨å€™...";
  translationBox.textContent = "";

  const userPrompt = [
    { type: "text", text: question }
  ];

  fetch("/api/analyze", {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({ messages: userPrompt })
  })
    .then(res => res.json())
    .then(data => {
      const answer = data.response || "âŒ ç„¡æ³•ç²å–è‹±æ–‡å›ç­”ã€‚";
      const translated = data.translated || "âŒ ç„¡æ³•ç¿»è­¯ç‚ºä¸­æ–‡ã€‚";
      const didStream = data.didStreamUrl;

      responseBox.textContent = answer;
      translationBox.textContent = `ğŸ‡¨ğŸ‡³ ä¸­æ–‡ç¿»è­¯ï¼š${translated}`;

      speakWithMyVoice(answer);
      if (didStream) switchToDIDStream(didStream);

      addToHistory(question, `${answer}<br><em>ğŸ‡¨ğŸ‡³ ä¸­æ–‡ç¿»è­¯ï¼š</em>${translated}`);
    })
    .catch(err => {
      responseBox.textContent = "âŒ ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œé‡è©¦ã€‚";
      console.error("GPT error:", err);
    });

  questionInput.value = "";
}

// ================================================================
// Step 4: Add Q&A to history
// ================================================================
function addToHistory(question, answer) {
  const li = document.createElement("li");
  li.innerHTML = `<strong>å•ï¼š</strong>${question}<br/><strong>ç­”ï¼š</strong>${answer}`;
  historyList.prepend(li);
}

// ================================================================
// Step 5: ElevenLabs Voice Output
// ================================================================
async function speakWithMyVoice(text) {
  try {
    const res = await fetch("/api/speak", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ text })
    });

    const data = await res.json();
    if (data.didStreamUrl) {
      switchToDIDStream(data.didStreamUrl);
    }

    if (data.audioBase64) {
      const audio = new Audio(`data:audio/mpeg;base64,${data.audioBase64}`);
      audio.play();
    }
  } catch (err) {
    console.error("ğŸ¤ Voice error:", err);
  }
}

// ================================================================
// Step 6: Avatar Stream Handling
// ================================================================
function switchToDIDStream(streamUrl) {
  const iframe = document.getElementById("didVideo");
  const staticAvatar = document.getElementById("avatarImage");
  iframe.src = streamUrl;
  iframe.style.display = "block";
  staticAvatar.style.display = "none";
  console.log("ğŸ¥ D-ID stream activated:", streamUrl);
}

// ================================================================
// Step 7: Mic Input (Hold-to-Speak)
// ================================================================
if (window.SpeechRecognition || window.webkitSpeechRecognition) {
  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
  const recognition = new SpeechRecognition();
  recognition.lang = "en-US"; // allow Dora to say phrasal verbs in English
  recognition.continuous = false;
  recognition.interimResults = false;

  let finalTranscript = "";
  let isHoldingMic = false;
  let restartCount = 0;
  const maxRestarts = 3;

  recognition.onstart = () => {
    micBtn.textContent = "ğŸ¤ æ­£åœ¨éŒ„éŸ³... (æ¾é–‹å¾Œæäº¤)";
    console.log("ğŸ™ï¸ Mic started");
  };

  recognition.onresult = (event) => {
    finalTranscript = event.results[0][0].transcript;
    console.log("ğŸ“¥ Captured:", finalTranscript);
  };

  recognition.onend = () => {
    if (isHoldingMic && restartCount < maxRestarts) {
      console.log("ğŸ” Restarting mic");
      restartCount++;
      recognition.start();
    } else {
      micBtn.textContent = "ğŸ¤ èªéŸ³æå•";
      if (finalTranscript.trim()) {
        questionInput.value = finalTranscript;
        submitQuestion();
      } else {
        console.log("âš ï¸ æ²’æœ‰æª¢æ¸¬åˆ°èªéŸ³å…§å®¹");
      }
    }
  };

  recognition.onerror = (event) => {
    console.error("ğŸ¤ Speech error:", event.error);
    micBtn.textContent = "ğŸ¤ èªéŸ³æå•";
  };

  micBtn.addEventListener("mousedown", () => {
    isHoldingMic = true;
    restartCount = 0;
    finalTranscript = "";
    recognition.start();
  });

  micBtn.addEventListener("mouseup", () => {
    isHoldingMic = false;
    recognition.stop();
  });

  micBtn.addEventListener("touchstart", () => {
    isHoldingMic = true;
    restartCount = 0;
    finalTranscript = "";
    recognition.start();
  });

  micBtn.addEventListener("touchend", () => {
    isHoldingMic = false;
    recognition.stop();
  });
}

// ================================================================
// Step 8: Bind global functions
// ================================================================
document.addEventListener("DOMContentLoaded", () => {
  window.submitQuestion = submitQuestion;
  window.setExam = setExam;
  window.clearHistory = clearHistory;
});

